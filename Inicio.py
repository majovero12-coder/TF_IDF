import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd
import re
from nltk.stem import SnowballStemmer

# --- ConfiguraciÃ³n de la pÃ¡gina ---
st.set_page_config(
    page_title="Demo TF-IDF Q&A",
    page_icon="ðŸ’¬",
    layout="centered"
)

# --- Estilos personalizados ---
st.markdown("""
    <style>
    /* Fondo general */
    .stApp {
        background: linear-gradient(135deg, #f7f7fa, #e8ebf7);
        color: #1b1b1b;
        font-family: "Inter", sans-serif;
    }

    /* TÃ­tulo */
    h1 {
        color: #5b32b4; /* violeta */
        text-align: center;
        font-weight: 800;
        padding-bottom: 0.5rem;
    }

    /* SubtÃ­tulos */
    h2, h3 {
        color: #30408d; /* azul oscuro */
        font-weight: 700;
        margin-top: 1rem;
    }

    /* Cuadros de texto */
    textarea, input {
        border-radius: 10px !important;
        border: 1px solid #b3b6d3 !important;
        background-color: #ffffff !important;
    }

    /* BotÃ³n principal */
    div.stButton > button {
        background-color: #5b32b4;
        color: white;
        font-weight: 600;
        border: none;
        border-radius: 10px;
        padding: 0.6rem 1rem;
        transition: all 0.3s ease;
        box-shadow: 0px 3px 6px rgba(0,0,0,0.2);
    }
    div.stButton > button:hover {
        background-color: #7b52d9;
        transform: scale(1.05);
        box-shadow: 0px 4px 8px rgba(0,0,0,0.25);
    }

    /* Tablas */
    .dataframe {
        border-radius: 8px;
        border: 1px solid #d1d3e0;
        overflow: hidden;
    }

    /* Textos */
    p, li {
        color: #2a2a2a !important;
        font-size: 1rem;
    }

    /* Explicaciones */
    .stMarkdown {
        color: #3c3c3c;
        font-size: 1rem;
    }
    </style>
""", unsafe_allow_html=True)

# --- TÃ­tulo principal ---
st.title("ðŸ’¬ Demo de TF-IDF con Preguntas y Respuestas")

st.write("""
Cada lÃ­nea se trata como un **documento** (puede ser una frase, un pÃ¡rrafo o un texto mÃ¡s largo).  
âš ï¸ Los documentos y las preguntas deben estar en **inglÃ©s**, ya que el anÃ¡lisis estÃ¡ configurado para ese idioma.  

La aplicaciÃ³n aplica normalizaciÃ³n y *stemming* para que palabras como *playing* y *play* se consideren equivalentes.
""")

# --- Entrada de texto ---
text_input = st.text_area(
    "ðŸ“ Escribe tus documentos (uno por lÃ­nea, en inglÃ©s):",
    "The dog barks loudly.\nThe cat meows at night.\nThe dog and the cat play together."
)

question = st.text_input("ðŸ” Escribe una pregunta (en inglÃ©s):", "Who is playing?")

# --- ConfiguraciÃ³n del stemmer ---
stemmer = SnowballStemmer("english")

def tokenize_and_stem(text: str):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', ' ', text)
    tokens = [t for t in text.split() if len(t) > 1]
    stems = [stemmer.stem(t) for t in tokens]
    return stems

# --- BotÃ³n para ejecutar ---
if st.button("ðŸš€ Calcular TF-IDF y buscar respuesta", use_container_width=True):
    documents = [d.strip() for d in text_input.split("\n") if d.strip()]
    if len(documents) < 1:
        st.warning("âš ï¸ Ingresa al menos un documento.")
    else:
        # VectorizaciÃ³n con stemming
        vectorizer = TfidfVectorizer(
            tokenizer=tokenize_and_stem,
            stop_words="english",
            token_pattern=None
        )

        X = vectorizer.fit_transform(documents)

        # Matriz TF-IDF
        df_tfidf = pd.DataFrame(
            X.toarray(),
            columns=vectorizer.get_feature_names_out(),
            index=[f"Doc {i+1}" for i in range(len(documents))]
        )

        st.subheader("ðŸ“Š Matriz TF-IDF (stems)")
        st.dataframe(df_tfidf.round(3))

        # Similaridad coseno con la pregunta
        question_vec = vectorizer.transform([question])
        similarities = cosine_similarity(question_vec, X).flatten()

        best_idx = similarities.argmax()
        best_doc = documents[best_idx]
        best_score = similarities[best_idx]

        st.subheader("ðŸ’¡ Resultado de bÃºsqueda")
        st.write(f"**Tu pregunta:** {question}")
        st.write(f"**Documento mÃ¡s relevante (Doc {best_idx+1}):** {best_doc}")
        st.success(f"**Puntaje de similitud:** {best_score:.3f}")

        sim_df = pd.DataFrame({
            "Documento": [f"Doc {i+1}" for i in range(len(documents))],
            "Texto": documents,
            "Similitud": similarities
        })
        st.subheader("ðŸ“ˆ Puntajes de similitud (ordenados)")
        st.dataframe(sim_df.sort_values("Similitud", ascending=False))

        vocab = vectorizer.get_feature_names_out()
        q_stems = tokenize_and_stem(question)
        matched = [s for s in q_stems if s in vocab and df_tfidf.iloc[best_idx].get(s, 0) > 0]
        st.subheader("ðŸ§© Stems de la pregunta presentes en el documento elegido")
        st.write(matched)





